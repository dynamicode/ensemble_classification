in 1998 and again in 1999, the lincoln laboratory of mit conducted a comparative evaluation of intrusion detection systems (idss) developed under darpa funding. while this evaluation represents a significant and monumental undertaking, there are a number of issues associated with its design and execution that remain unsettled. some methodologies used in the evaluation are questionable and may have biased its results. one problem is that the evaluators have published relatively little concerning some of the more critical aspects of their work, such as validation of their test data. the appropriateness of the evaluation techniques used needs further investigation. the purpose of this article is to attempt to identify the shortcomings of the lincoln lab effort in the hope that future  efforts of this kind will be placed on a sounder footing. some of the problems that the article points out might well be resolved if the evaluators were to publish a detailed description of their procedures and the rationale that led to their adoption, but other problems would clearly remain./par>testing intrusion detection systems: a critique of the 1998 and 1999 darpa intrusion detection system evaluations as performed by lincoln laboratory